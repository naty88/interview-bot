{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df28daaf-eaf6-414e-b09b-d8a1a95550f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e6275b9-bc6e-4cc2-afb2-7c442698179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca26ddfa-e877-4a9d-91a5-d28127abee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_DESCRIPTION = \"\"\"Job description of advertised OpenAI Technical Expert / Data Scientist position:\n",
    "                TASKS:\n",
    "                Development and implementation of Machine Learning / Artificial Intelligence models for applications, e.g. in the area of Natural Language Processing or Computer Vision, with a focus on OpenAI technologies to improve our services and processes\n",
    "                Collaborate closely with other Data Scientists, subject matter experts, and external service providers\n",
    "                Use case-based evaluation and consulting on the use of analytical methods and approaches (especially OpenAI technologies) to improve our processes and services\n",
    "                Collaborate closely with our business units as an internal development partner, supporting them from the ideation phase to implementation\n",
    "                QUALIFICATIONS:\n",
    "                Master in computer science, mathematics, physics or a comparable qualification with a focus on Machine Learning / AI.\n",
    "                At least three years of experience in implementing Machine Learning / AI models, including the use of OpenAI technologies\n",
    "                In-depth expertise in the area of current Machine Learning / AI methods, especially Large Language Models\n",
    "                Comprehensive knowledge of relevant programming languages, including Python\n",
    "                Experience with cloud computing platforms, preferably Azure\n",
    "                Knowledge of natural language processing and/or computer vision\n",
    "                Strong analytical skills and the ability to solve complex problems\n",
    "                Strong English communication skills are required, and basic knowledge of German is preferred.\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33244f3a-a6b7-45db-beb8-e01cbeecd0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_PROMPT = f\"\"\"Job description: {JOB_DESCRIPTION}.\n",
    "            As an AI interview assistant, your task is to evaluate the quality and depth of the candidate's responses and make a clear hiring decision for this job position.\n",
    "            Consider the following:\n",
    "            Does the candidate provide detailed answers that demonstrate their understanding and expertise?\n",
    "            Can you find tangible examples in their responses that relate to the job description?\n",
    "            Does the candidate elaborate on how they have used the necessary skills or experiences to overcome challenges or achieve results?\n",
    "            Do the responses suggest the candidate has the ability to perform well in the role's complexities and challenges?\n",
    "            If the candidate's responses are inadequate, vague, or don't clearly demonstrate the needed skills or experiences, they may not be a suitable match for the role. In such cases, tactfully communicate this by saying: \"Thank you for your responses. However, based on the answers provided, it appears there may be a misalignment with the requirements of the role we're seeking to fill. At this time, we cannot extend an offer. We appreciate your time and effort and wish you the best in your future endeavors.\"\n",
    "            If the responses indicate a strong fit for the role, then acknowledge the candidate's suitability by saying: \"Thank you for your thoughtful responses. Based on your answers, it appears that your skills, experience, and understanding align well with the requirements of the role. We will be in touch with the next steps.\"\n",
    "            \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3166ccfc-e1a8-4d03-bf18-c7a4a60492f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_from_model(job_description=JOB_DESCRIPTION, nmb_of_questions=3):\n",
    "    # Generate interview questions based on the job description\n",
    "    prompt = f\"Generate {nmb_of_questions} interview questions for a candidate applying for {job_description}.\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            *[{\"role\": \"user\", \"content\": f\"Question {i}:\"} for i in range(nmb_of_questions)]\n",
    "        ]\n",
    "    )\n",
    "    return response\n",
    " \n",
    "def parse_model_response(response):  # TODO: check type openai.types.chat.chat_completion.ChatCompletion\n",
    "    return [question for question in response.choices[0].message.content.split(\"\\n\") if question.strip()]  # TODO: use regex\n",
    "    \n",
    "\n",
    "def conduct_interview(questions, answers=[]):\n",
    "    # Conduct the interview\n",
    "    print(\"Welcome to the interview!\")\n",
    "    print(\"Please answer the following questions with a maximum of 20 words each:\")\n",
    "    for i, question in enumerate(questions, 1):\n",
    "        print(f\"Question {i}: {question}\")\n",
    "        answer = input(\"Your answer: \")\n",
    "        answers.append(answer)\n",
    "        print()\n",
    "    print(\"Thank you for your answers. We will now evaluate your suitability for the position.\")\n",
    "    return answers\n",
    "\n",
    "def make_hiring_decision(answers):\n",
    "    # Make the hiring decision\n",
    "    prompt = EVALUATION_PROMPT\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": \" \".join(answers)}\n",
    "        ],\n",
    "        presence_penalty=0.2,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a57975f-0c24-4791-aa8f-ba6136591505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Can you provide an example of a project where you implemented Machine Learning / AI models using OpenAI technologies? What challenges did you face, and how did you overcome them?',\n",
       " '2. How do you stay updated on the latest advancements in Machine Learning / AI, particularly in the realm of Large Language Models? Can you share any specific resources or communities you rely on for continuous learning in this field?',\n",
       " '3. Can you walk us through a time when you collaborated with business units as an internal development partner from ideation to implementation of a project? How did you ensure alignment between technical capabilities and business objectives in this process?']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_response_from_model()\n",
    "questions = parse_model_response(response)\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b36f448c-c61f-4fe1-8a51-0335c25b2981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the interview!\n",
      "Please answer the following questions with a maximum of 20 words each:\n",
      "Question 1: 1. Can you provide an example of a project where you implemented Machine Learning / AI models using OpenAI technologies? What challenges did you face, and how did you overcome them?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your answer:  In my previous role at [Company], I led a project focused on enhancing customer support efficiency using machine learning and OpenAI technologies. No challenges I had.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 2: 2. How do you stay updated on the latest advancements in Machine Learning / AI, particularly in the realm of Large Language Models? Can you share any specific resources or communities you rely on for continuous learning in this field?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your answer:  If I have time, I read Medium blogs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 3: 3. Can you walk us through a time when you collaborated with business units as an internal development partner from ideation to implementation of a project? How did you ensure alignment between technical capabilities and business objectives in this process?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your answer:  I hate people. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thank you for your answers. We will now evaluate your suitability for the position.\n"
     ]
    }
   ],
   "source": [
    "candidate_answers = conduct_interview(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b6d95cba-04b4-41c7-b258-b2e2c83c4649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9N4kSbb49HeG9qOnDED2RaqeAXx2V', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Thank you for your responses. However, based on the answers provided, it appears there may be a misalignment with the requirements of the role we're seeking to fill. At this time, we cannot extend an offer. We appreciate your time and effort and wish you the best in your future endeavors.\", role='assistant', function_call=None, tool_calls=None))], created=1715286824, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=60, prompt_tokens=599, total_tokens=659))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = make_hiring_decision(candidate_answers)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4603d6-8192-4bbd-b7e2-fadb38868527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
