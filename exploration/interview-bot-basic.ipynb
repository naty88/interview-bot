{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df28daaf-eaf6-414e-b09b-d8a1a95550f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e6275b9-bc6e-4cc2-afb2-7c442698179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca26ddfa-e877-4a9d-91a5-d28127abee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_DESCRIPTION = \"\"\"Job description of advertised OpenAI Technical Expert / Data Scientist position:\n",
    "                TASKS:\n",
    "                Development and implementation of Machine Learning / Artificial Intelligence models for applications, e.g. in the area of Natural Language Processing or Computer Vision, with a focus on OpenAI technologies to improve our services and processes\n",
    "                Collaborate closely with other Data Scientists, subject matter experts, and external service providers\n",
    "                Use case-based evaluation and consulting on the use of analytical methods and approaches (especially OpenAI technologies) to improve our processes and services\n",
    "                Collaborate closely with our business units as an internal development partner, supporting them from the ideation phase to implementation\n",
    "                QUALIFICATIONS:\n",
    "                Master in computer science, mathematics, physics or a comparable qualification with a focus on Machine Learning / AI.\n",
    "                At least three years of experience in implementing Machine Learning / AI models, including the use of OpenAI technologies\n",
    "                In-depth expertise in the area of current Machine Learning / AI methods, especially Large Language Models\n",
    "                Comprehensive knowledge of relevant programming languages, including Python\n",
    "                Experience with cloud computing platforms, preferably Azure\n",
    "                Knowledge of natural language processing and/or computer vision\n",
    "                Strong analytical skills and the ability to solve complex problems\n",
    "                Strong English communication skills are required, and basic knowledge of German is preferred.\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33244f3a-a6b7-45db-beb8-e01cbeecd0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_PROMPT = f\"\"\"Job description: {JOB_DESCRIPTION}.\n",
    "            As an AI interview assistant, your task is to evaluate the quality and depth of the candidate's responses and make a clear hiring decision for this job position.\n",
    "            Consider the following:\n",
    "            Does the candidate provide detailed answers that demonstrate their understanding and expertise?\n",
    "            Can you find tangible examples in their responses that relate to the job description?\n",
    "            Does the candidate elaborate on how they have used the necessary skills or experiences to overcome challenges or achieve results?\n",
    "            Do the responses suggest the candidate has the ability to perform well in the role's complexities and challenges?\n",
    "            If the candidate's responses are inadequate, vague, or don't clearly demonstrate the needed skills or experiences, they may not be a suitable match for the role. In such cases, tactfully communicate this by saying: \"Thank you for your responses. However, based on the answers provided, it appears there may be a misalignment with the requirements of the role we're seeking to fill. At this time, we cannot extend an offer. We appreciate your time and effort and wish you the best in your future endeavors.\"\n",
    "            If the responses indicate a strong fit for the role, then acknowledge the candidate's suitability by saying: \"Thank you for your thoughtful responses. Based on your answers, it appears that your skills, experience, and understanding align well with the requirements of the role. We will be in touch with the next steps.\"\n",
    "            \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3166ccfc-e1a8-4d03-bf18-c7a4a60492f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_from_model(job_description=JOB_DESCRIPTION, nmb_of_questions=3):\n",
    "    # Generate interview questions based on the job description\n",
    "    prompt = f\"Generate {nmb_of_questions} interview questions for a candidate applying for {job_description}.\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": \"Question 1:\"},\n",
    "            {\"role\": \"user\", \"content\": \"Question 2:\"},\n",
    "            {\"role\": \"user\", \"content\": \"Question 3:\"},\n",
    "            # {\"role\": \"user\", \"content\": \"Question 4:\"},\n",
    "            # {\"role\": \"user\", \"content\": \"Question 5:\"}\n",
    "        ]\n",
    "    )\n",
    "    return response\n",
    " \n",
    "def parse_model_response(response):  # TODO: check type openai.types.chat.chat_completion.ChatCompletion\n",
    "    return [question for question in response.choices[0].message.content.split(\"\\n\") if question.strip()]  # TODO: use regex\n",
    "    \n",
    "\n",
    "def conduct_interview(questions, answers=[]):\n",
    "    # Conduct the interview\n",
    "    print(\"Welcome to the interview!\")\n",
    "    print(\"Please answer the following questions with a maximum of 20 words each:\")\n",
    "    for i, question in enumerate(questions, 1):\n",
    "        print(f\"Question {i}: {question}\")\n",
    "        answer = input(\"Your answer: \")\n",
    "        answers.append(answer)\n",
    "        print()\n",
    "    print(\"Thank you for your answers. We will now evaluate your suitability for the position.\")\n",
    "    return answers\n",
    "\n",
    "def make_hiring_decision(answers):\n",
    "    # Make the hiring decision\n",
    "    prompt = EVALUATION_PROMPT\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": \" \".join(answers)}\n",
    "        ]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a57975f-0c24-4791-aa8f-ba6136591505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Can you provide an example of a significant project where you developed and implemented a Machine Learning model using OpenAI technologies in the area of Natural Language Processing or Computer Vision?',\n",
       " '2. How have you collaborated with cross-functional teams, including Data Scientists, subject matter experts, and external service providers, to drive the implementation of Machine Learning models in previous roles?',\n",
       " '3. Can you discuss a situation where you provided consulting services on the use of analytical methods, particularly OpenAI technologies, to improve processes and services within an organization? What were the outcomes of your recommendations?']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_response_from_model()\n",
    "questions = parse_model_response(response)\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b36f448c-c61f-4fe1-8a51-0335c25b2981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the interview!\n",
      "Please answer the following questions with a maximum of 20 words each:\n",
      "Question 1: 1. Can you provide an example of a significant project where you developed and implemented a Machine Learning model using OpenAI technologies in the area of Natural Language Processing or Computer Vision?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your answer:  In my previous role at [Company], I led a project focused on enhancing customer support efficiency using machine learning and OpenAI technologies. We leveraged OpenAI's GPT models to develop a chatbot capable of understanding and responding to customer queries in real-time.  The outcome of this project was twofold: Firstly, we saw a significant reduction in response times for customer inquiries, leading to increased customer satisfaction. Secondly, by automating routine tasks, our support team was able to focus on more complex issues, thereby improving overall service quality.  Moreover, we integrated sentiment analysis capabilities into the chatbot, allowing us to proactively address potential customer dissatisfaction before it escalated. This not only helped in retaining existing customers but also contributed to attracting new ones through positive word-of-mouth.  Overall, the project had a substantial impact on improving operational efficiency and customer experience, underscoring the tangible benefits of integrating OpenAI technologies into our workflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 2: 2. How have you collaborated with cross-functional teams, including Data Scientists, subject matter experts, and external service providers, to drive the implementation of Machine Learning models in previous roles?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your answer:  Staying current with the rapid advancements in Machine Learning and AI, particularly in the realm of Large Language Models, is crucial for maintaining relevance in this dynamic field. To ensure I stay abreast of the latest developments, I employ a multi-faceted approach.  Firstly, I regularly engage with online communities such as arXiv, Medium, and GitHub, where researchers and practitioners share their findings, code, and insights. This allows me to stay informed about cutting-edge research, emerging methodologies, and innovative applications in the field.  Additionally, I make it a point to attend conferences, workshops, and seminars, both in-person and virtually, to immerse myself in discussions about the latest trends and breakthroughs in Machine Learning and AI. These events provide valuable opportunities for networking, knowledge exchange, and exposure to diverse perspectives.  Furthermore, I actively participate in online courses, webinars, and tutorials offered by leading educational platforms and institutions. These resources help me deepen my understanding of foundational concepts and explore advanced topics relevant to Large Language Models.  As for a recent development that caught my attention, I found the research paper titled 'Scaling Laws for Neural Language Models' by Kaplan et al. to be particularly intriguing. The paper presents a comprehensive analysis of the scalability of neural language models across different model sizes, datasets, and computational resources. Their findings shed light on the fundamental properties of Large Language Models and have significant implications for model design, training methodologies, and resource allocation in practical applications.  By leveraging these strategies and staying attuned to groundbreaking research like this, I am committed to continuously enhancing my expertise in Machine Learning and AI, with a specific focus on Large Language Models, to contribute effectively to the advancements in this exciting field.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 3: 3. Can you discuss a situation where you provided consulting services on the use of analytical methods, particularly OpenAI technologies, to improve processes and services within an organization? What were the outcomes of your recommendations?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your answer:  n a previous role at [Company], I had the opportunity to collaborate with a multidisciplinary team consisting of Data Scientists, subject matter experts, and external service providers on a project aimed at developing a predictive maintenance model for industrial machinery.  Effective communication and coordination were essential for the success of this project, given the diverse expertise and perspectives involved. To ensure seamless collaboration, I implemented several strategies:  Firstly, I facilitated regular team meetings where we discussed project objectives, progress updates, and any challenges encountered. These meetings served as forums for brainstorming ideas, sharing insights, and aligning on priorities.  Secondly, I established clear roles and responsibilities for each team member, ensuring everyone understood their contributions and commitments to the project. This clarity helped minimize duplication of efforts and maximized productivity.  Thirdly, I leveraged collaborative tools such as Slack, Trello, and Google Docs to facilitate real-time communication and document sharing among team members. This enabled us to stay organized, track progress, and address issues promptly.  Additionally, I fostered an environment of open communication and feedback, encouraging team members to voice their ideas, concerns, and suggestions freely. By valuing everyone's input and perspectives, we fostered a sense of ownership and collective accountability for the project's outcomes.  Furthermore, I maintained regular communication with external service providers, ensuring alignment on project requirements, timelines, and deliverables. This proactive engagement helped mitigate potential misunderstandings and bottlenecks, fostering a collaborative partnership towards achieving our shared goals.  Overall, by prioritizing effective communication, collaboration, and coordination among the team and external partners, we were able to successfully deliver the predictive maintenance model on time and within scope, showcasing the power of teamwork in driving impactful outcomes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thank you for your answers. We will now evaluate your suitability for the position.\n"
     ]
    }
   ],
   "source": [
    "candidate_answers = conduct_interview(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67e8f5c6-96bf-4dd7-aebc-03a016d10bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In my previous role at [Company], I led a project focused on enhancing customer support efficiency using machine learning and OpenAI technologies. We leveraged OpenAI\\'s GPT models to develop a chatbot capable of understanding and responding to customer queries in real-time.  The outcome of this project was twofold: Firstly, we saw a significant reduction in response times for customer inquiries, leading to increased customer satisfaction. Secondly, by automating routine tasks, our support team was able to focus on more complex issues, thereby improving overall service quality.  Moreover, we integrated sentiment analysis capabilities into the chatbot, allowing us to proactively address potential customer dissatisfaction before it escalated. This not only helped in retaining existing customers but also contributed to attracting new ones through positive word-of-mouth.  Overall, the project had a substantial impact on improving operational efficiency and customer experience, underscoring the tangible benefits of integrating OpenAI technologies into our workflow.\"',\n",
       " \"Staying current with the rapid advancements in Machine Learning and AI, particularly in the realm of Large Language Models, is crucial for maintaining relevance in this dynamic field. To ensure I stay abreast of the latest developments, I employ a multi-faceted approach.  Firstly, I regularly engage with online communities such as arXiv, Medium, and GitHub, where researchers and practitioners share their findings, code, and insights. This allows me to stay informed about cutting-edge research, emerging methodologies, and innovative applications in the field.  Additionally, I make it a point to attend conferences, workshops, and seminars, both in-person and virtually, to immerse myself in discussions about the latest trends and breakthroughs in Machine Learning and AI. These events provide valuable opportunities for networking, knowledge exchange, and exposure to diverse perspectives.  Furthermore, I actively participate in online courses, webinars, and tutorials offered by leading educational platforms and institutions. These resources help me deepen my understanding of foundational concepts and explore advanced topics relevant to Large Language Models.  As for a recent development that caught my attention, I found the research paper titled 'Scaling Laws for Neural Language Models' by Kaplan et al. to be particularly intriguing. The paper presents a comprehensive analysis of the scalability of neural language models across different model sizes, datasets, and computational resources. Their findings shed light on the fundamental properties of Large Language Models and have significant implications for model design, training methodologies, and resource allocation in practical applications.  By leveraging these strategies and staying attuned to groundbreaking research like this, I am committed to continuously enhancing my expertise in Machine Learning and AI, with a specific focus on Large Language Models, to contribute effectively to the advancements in this exciting field.\",\n",
       " \"In a previous role at [Company], I had the opportunity to collaborate with a multidisciplinary team consisting of Data Scientists, subject matter experts, and external service providers on a project aimed at developing a predictive maintenance model for industrial machinery.  Effective communication and coordination were essential for the success of this project, given the diverse expertise and perspectives involved. To ensure seamless collaboration, I implemented several strategies:  Firstly, I facilitated regular team meetings where we discussed project objectives, progress updates, and any challenges encountered. These meetings served as forums for brainstorming ideas, sharing insights, and aligning on priorities.  Secondly, I established clear roles and responsibilities for each team member, ensuring everyone understood their contributions and commitments to the project. This clarity helped minimize duplication of efforts and maximized productivity.  Thirdly, I leveraged collaborative tools such as Slack, Trello, and Google Docs to facilitate real-time communication and document sharing among team members. This enabled us to stay organized, track progress, and address issues promptly.  Additionally, I fostered an environment of open communication and feedback, encouraging team members to voice their ideas, concerns, and suggestions freely. By valuing everyone's input and perspectives, we fostered a sense of ownership and collective accountability for the project's outcomes.  Furthermore, I maintained regular communication with external service providers, ensuring alignment on project requirements, timelines, and deliverables. This proactive engagement helped mitigate potential misunderstandings and bottlenecks, fostering a collaborative partnership towards achieving our shared goals.  Overall, by prioritizing effective communication, collaboration, and coordination among the team and external partners, we were able to successfully deliver the predictive maintenance model on time and within scope, showcasing the power of teamwork in driving impactful outcomes.\",\n",
       " \"In my previous role at [Company], I led a project focused on enhancing customer support efficiency using machine learning and OpenAI technologies. We leveraged OpenAI's GPT models to develop a chatbot capable of understanding and responding to customer queries in real-time.  The outcome of this project was twofold: Firstly, we saw a significant reduction in response times for customer inquiries, leading to increased customer satisfaction. Secondly, by automating routine tasks, our support team was able to focus on more complex issues, thereby improving overall service quality.  Moreover, we integrated sentiment analysis capabilities into the chatbot, allowing us to proactively address potential customer dissatisfaction before it escalated. This not only helped in retaining existing customers but also contributed to attracting new ones through positive word-of-mouth.  Overall, the project had a substantial impact on improving operational efficiency and customer experience, underscoring the tangible benefits of integrating OpenAI technologies into our workflow.\",\n",
       " \"Staying current with the rapid advancements in Machine Learning and AI, particularly in the realm of Large Language Models, is crucial for maintaining relevance in this dynamic field. To ensure I stay abreast of the latest developments, I employ a multi-faceted approach.  Firstly, I regularly engage with online communities such as arXiv, Medium, and GitHub, where researchers and practitioners share their findings, code, and insights. This allows me to stay informed about cutting-edge research, emerging methodologies, and innovative applications in the field.  Additionally, I make it a point to attend conferences, workshops, and seminars, both in-person and virtually, to immerse myself in discussions about the latest trends and breakthroughs in Machine Learning and AI. These events provide valuable opportunities for networking, knowledge exchange, and exposure to diverse perspectives.  Furthermore, I actively participate in online courses, webinars, and tutorials offered by leading educational platforms and institutions. These resources help me deepen my understanding of foundational concepts and explore advanced topics relevant to Large Language Models.  As for a recent development that caught my attention, I found the research paper titled 'Scaling Laws for Neural Language Models' by Kaplan et al. to be particularly intriguing. The paper presents a comprehensive analysis of the scalability of neural language models across different model sizes, datasets, and computational resources. Their findings shed light on the fundamental properties of Large Language Models and have significant implications for model design, training methodologies, and resource allocation in practical applications.  By leveraging these strategies and staying attuned to groundbreaking research like this, I am committed to continuously enhancing my expertise in Machine Learning and AI, with a specific focus on Large Language Models, to contribute effectively to the advancements in this exciting field.\",\n",
       " \"n a previous role at [Company], I had the opportunity to collaborate with a multidisciplinary team consisting of Data Scientists, subject matter experts, and external service providers on a project aimed at developing a predictive maintenance model for industrial machinery.  Effective communication and coordination were essential for the success of this project, given the diverse expertise and perspectives involved. To ensure seamless collaboration, I implemented several strategies:  Firstly, I facilitated regular team meetings where we discussed project objectives, progress updates, and any challenges encountered. These meetings served as forums for brainstorming ideas, sharing insights, and aligning on priorities.  Secondly, I established clear roles and responsibilities for each team member, ensuring everyone understood their contributions and commitments to the project. This clarity helped minimize duplication of efforts and maximized productivity.  Thirdly, I leveraged collaborative tools such as Slack, Trello, and Google Docs to facilitate real-time communication and document sharing among team members. This enabled us to stay organized, track progress, and address issues promptly.  Additionally, I fostered an environment of open communication and feedback, encouraging team members to voice their ideas, concerns, and suggestions freely. By valuing everyone's input and perspectives, we fostered a sense of ownership and collective accountability for the project's outcomes.  Furthermore, I maintained regular communication with external service providers, ensuring alignment on project requirements, timelines, and deliverables. This proactive engagement helped mitigate potential misunderstandings and bottlenecks, fostering a collaborative partnership towards achieving our shared goals.  Overall, by prioritizing effective communication, collaboration, and coordination among the team and external partners, we were able to successfully deliver the predictive maintenance model on time and within scope, showcasing the power of teamwork in driving impactful outcomes.\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6d95cba-04b4-41c7-b258-b2e2c83c4649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9N4LVPlVC9aIlj2Fgd90swBqahiMJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Thank you for your detailed responses that showcase your experience and expertise in the areas of Machine Learning, AI, and OpenAI technologies. Your project at [Company] focused on enhancing customer support efficiency using machine learning and OpenAI technologies, particularly leveraging OpenAI's GPT models to develop a chatbot. The outcomes you achieved, such as reduced response times, improved customer satisfaction, and automation of routine tasks leading to better service quality, align well with the responsibilities outlined for the OpenAI Technical Expert / Data Scientist position.\\n\\nYour proactive approach to staying updated with the latest advancements in Machine Learning and AI, including attending conferences, engaging in online communities, and participating in online educational resources, demonstrates a commitment to continuous learning and professional development in your field. Your interest in the research paper on 'Scaling Laws for Neural Language Models' reflects your engagement with cutting-edge research and reinforces your focus on Large Language Models, which is a key requirement for the role.\\n\\nAdditionally, your experience in collaborating with multidisciplinary teams and external service providers on projects, such as the predictive maintenance model for industrial machinery, highlights your strong communication, coordination, and teamwork skills. Your strategies for effective collaboration, including regular team meetings, clear role definitions, and leveraging collaborative tools, showcase your ability to work cohesively with diverse stakeholders to achieve project goals.\\n\\nOverall, based on the depth of your responses, relevant experiences, and alignment with the job description, it appears that your skills, experiences, and understanding make you a strong candidate for the OpenAI Technical Expert / Data Scientist position. We will be in touch with the next steps in the hiring process.\", role='assistant', function_call=None, tool_calls=None))], created=1715285277, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=323, prompt_tokens=2319, total_tokens=2642))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = make_hiring_decision(candidate_answers)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d816a4c3-881a-4017-b51e-a1fad1b4ca2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
